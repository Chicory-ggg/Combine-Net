{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_pruning as pruning\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from kneed import KneeLocator\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d771b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_epoches = 10\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ef31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # 2\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # 4\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 5\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # 6\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # 7\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 8\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # 9\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # 10\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 11\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # 12\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # 13\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            # 14\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            # 15\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            # 16\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        # self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        #        print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #        print(out.shape)\n",
    "        out = self.classifier(out)\n",
    "        #        print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluteTop1(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = len(loader.dataset)\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += torch.eq(pred, y).sum().float().item()\n",
    "        # correct += torch.eq(pred, y).sum().item()\n",
    "    print(correct / total)\n",
    "    return correct / total\n",
    "\n",
    "#Adaptive BN\n",
    "def eval_pruning_strategy(model, dataloader_train):\n",
    "   # Adaptive-BN\n",
    "   model.train()\n",
    "   max_iter = 100\n",
    "   with torch.no_grad():\n",
    "      for iter_in_epoch, (data1,label1) in enumerate(dataloader_train):\n",
    "            data1, label1 = data1.cuda(), label1.cuda()\n",
    "            model.forward(data1)\n",
    "            if iter_in_epoch > max_iter:\n",
    "                break\n",
    "\n",
    "#Return Conv_Rank\n",
    "def calculate_conv_weight_idx(model,layer_number):\n",
    "    prunable_module_type = (nn.Conv2d)\n",
    "    prunable_modules = [m for m in model.modules() if isinstance(m, prunable_module_type)]\n",
    "    layer_to_calculate = prunable_modules[layer_number]\n",
    "    conv_weight = layer_to_calculate.weight\n",
    "    total_cov_weight = []\n",
    "    for i in range(conv_weight.__len__()):\n",
    "        filter_now = conv_weight[i]\n",
    "        filter_view = torch.reshape(input=filter_now, shape=(1, -1))\n",
    "        total_weight = sum(sum(abs(filter_view)))\n",
    "        total_weight = total_weight.cpu()\n",
    "        total_weight_list = total_weight.detach().numpy().tolist()\n",
    "        total_cov_weight.append(total_weight_list)\n",
    "    sorted_nums = sorted(enumerate(total_cov_weight), key=lambda x: x[1])\n",
    "    idx = [i[0] for i in sorted_nums]\n",
    "    nums = [i[1] for i in sorted_nums]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453266de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knowledge_distillation\n",
    "teacher_model = torch.load(\"VGGNet16_cifar10_original.pth\")\n",
    "\n",
    "def distillation(y, labels, teacher_scores, temp, alpha):\n",
    "    return nn.KLDivLoss()(F.log_softmax(y / temp, dim=1), F.softmax(teacher_scores / temp, dim=1)) * (\n",
    "            temp * temp * 2.0 * alpha) + F.cross_entropy(y, labels) * (1. - alpha)\n",
    "\n",
    "def train_student_kd(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    trained_samples = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        teacher_output = teacher_model(data)\n",
    "        teacher_output = teacher_output.detach()  \n",
    "        loss = distillation(output, target, teacher_output, temp=5.0, alpha=0.7)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        trained_samples += len(data)\n",
    "        progress = math.ceil(batch_idx / len(train_loader) * 50)\n",
    "        print(\"\\rTrain epoch %d: %d/%d, [%-51s] %d%%\" %\n",
    "              (epoch, trained_samples, len(train_loader.dataset),\n",
    "               '-' * progress + '>', progress * 2), end='')\n",
    "\n",
    "def student_kd_main():\n",
    "    model = torch.load(\"model_pruned.pth\")\n",
    "    epochs = 5\n",
    "    torch.manual_seed(0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),1e-4)\n",
    "    student_history = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_student_kd(model, device, trainloader, optimizer, epoch)\n",
    "        acc=evaluteTop1(model,testloader)\n",
    "        student_history.append(acc)\n",
    "    torch.save(model, \"model_pruned.pth\")\n",
    "    return model, student_history\n",
    "\n",
    "# Renturn layer number\n",
    "def chooselayer(model,layer):\n",
    "    prunable_module_type = (nn.Conv2d)\n",
    "    prunable_modules = [m for m in model.modules() if isinstance(m, prunable_module_type)]\n",
    "    layer_to_calculate = prunable_modules[layer]\n",
    "    return layer_to_calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new model  \n",
    "weights_path = \"VGGNet16_cifar10_original.pth\"\n",
    "model = torch.load(weights_path, map_location=device)\n",
    "torch.save(model, \"model_pruned.pth\")\n",
    "\n",
    "for layer in range(13):\n",
    "    rate_conv = []\n",
    "    acc_cov = []\n",
    "    idx_now=calculate_conv_weight_idx(model,layer)\n",
    "    for temp in range(20):\n",
    "        print(\"Layer is:\",layer,\", epoch is :\",temp)        \n",
    "        DG = pruning.DependencyGraph()\n",
    "        DG.build_dependency(model_temp, example_inputs=torch.randn(1,3,32,32))\n",
    "        weights_path = \"model_pruned.pth\"\n",
    "        model_temp = torch.load(weights_path, map_location=device)\n",
    "        layer_to_calculate = chooselayer(model_temp,layer)\n",
    "        ch = pruning.utils.count_prunable_channels(layer_to_calculate)\n",
    "        prune_acc=temp*5/100\n",
    "        idx_number=int(prune_acc*ch)\n",
    "        weight_idx = idx_now[0:idx_number]\n",
    "        pruning_plan = DG.get_pruning_plan(layer_to_calculate, pruning.prune_conv, idxs=weight_idx )\n",
    "        pruning_plan.exec()\n",
    "        model_temp = model_temp.cuda()\n",
    "        #Adaptive BN\n",
    "        eval_pruning_strategy(model_temp, trainloader)\n",
    "        model_temp = model_temp.cuda()\n",
    "        temp_rate = temp / 20\n",
    "        rate_conv.append(temp_rate*100)\n",
    "        acc_cov.append(evaluteTop1(model_temp, testloader)*100)\n",
    "\n",
    "    #choose pruning rate \n",
    "    if acc_cov[0]-acc_cov[19]<=0.05:\n",
    "        cut_rate=rate_conv[19]/100\n",
    "    else:\n",
    "        kneedle_con_dec = KneeLocator(rate_conv,\n",
    "                                      acc_cov,\n",
    "                                      curve='concave',\n",
    "                                      direction='decreasing',\n",
    "                                      online=True)\n",
    "\n",
    "        cut_rate=kneedle_con_dec.knee/100\n",
    "    plt.plot(rate_conv, acc_cov, 'k--')\n",
    "    plt.scatter(x=kneedle_con_dec.knee, y=kneedle_con_dec.knee_y, c='b', s=200, marker='^', alpha=1)\n",
    "    plt.title('concave+decreasing')\n",
    "    plt.show()\n",
    "\n",
    "    #true prning\n",
    "    DG = pruning.DependencyGraph()\n",
    "    DG.build_dependency(model, example_inputs=torch.randn(1,3,32,32))\n",
    "    layer_to_calculate = chooselayer(model,layer)\n",
    "    ch = pruning.utils.count_prunable_channels(layer_to_calculate)\n",
    "    idx_number=int(cut_rate*ch)\n",
    "    weight_idx = idx_now[0:idx_number]\n",
    "    pruning_plan = DG.get_pruning_plan(layer_to_calculate, pruning.prune_conv, idxs=weight_idx )\n",
    "    pruning_plan.exec()\n",
    "    model = model.cuda()\n",
    "    eval_pruning_strategy(model, trainloader)\n",
    "    model = model.cuda()\n",
    "    print(\"Top-1 accuracy after prune is: \",evaluteTop1(model, testloader)*100)\n",
    "\n",
    "    torch.save(model, \"model_pruned.pth\")\n",
    "\n",
    "    student_simple_model, student_simple_history = student_kd_main()\n",
    "\n",
    "    print(\"Top-1 accuracy after retraning is:\",evaluteTop1(student_simple_model, testloader)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1901f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An 120 epoch overall finetuning is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee845b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
